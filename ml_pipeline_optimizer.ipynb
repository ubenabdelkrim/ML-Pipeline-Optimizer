{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8d7db1",
   "metadata": {},
   "source": [
    "# Introduction: Machine Learning for Geospatial Use Cases\n",
    "\n",
    "In recent years, geospatial data has gained significant attention due to its diverse applications in fields such as urban planning, environmental monitoring, and disaster management. The ability to model and predict patterns using geospatial data is critical for informed decision-making. However, working with geospatial datasets presents unique challenges, including handling high-dimensional data, managing spatial dependencies, and integrating various data sources with different resolutions and formats.\n",
    "\n",
    "This notebook focuses on leveraging **machine learning techniques**, particularly **XGBoost**, to address a geospatial use case. XGBoost is a powerful gradient boosting framework known for its efficiency and performance, especially in handling structured data. The workflow covered in this notebook includes the following stages:\n",
    "\n",
    "1. **Data Extraction**: Collecting geospatial data from multiple sources, such as satellite imagery, sensor networks, and public databases.\n",
    "2. **Data Preprocessing**: Cleaning and transforming the data to ensure compatibility with machine learning algorithms. This includes handling missing values, feature scaling, and encoding categorical variables.\n",
    "3. **Feature Engineering**: Creating meaningful features from raw geospatial data, including distance calculations, spatial aggregations, and temporal features.\n",
    "4. **Model Training and Evaluation**: Applying XGBoost to predict outcomes based on geospatial features. The model's performance is evaluated using appropriate metrics, and hyperparameters are tuned to improve accuracy.\n",
    "5. **Visualization**: Using geospatial visualization tools to interpret model outputs and understand spatial patterns in the data.\n",
    "\n",
    "The goal is to demonstrate how machine learning can be effectively applied to geospatial data, providing actionable insights and enhancing the decision-making process. This approach bridges the gap between traditional geospatial analysis and modern machine learning techniques, offering robust solutions to complex spatial problems.\n",
    "\n",
    "**Note**: This notebook does not include the entirety of the work done to improve the quality of predictions. Additional efforts, such as further hyperparameter tuning, advanced feature engineering, and model ensembling, have been undertaken to enhance the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a9ccb",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "To build and evaluate the machine learning model for our geospatial use case, we start by importing the necessary libraries. These include both standard libraries and third-party tools for data manipulation, visualization, and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ada74d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6918a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Configuration and constants\n",
    "BASE_URL = \"https://metrics.run.lithops.cloud/api/v1\"\n",
    "AUTH_TOKEN = \"AUTH_TOKEN\" # Ensure to replace with your actual token\n",
    "HEADERS = {'Authorization': f'Bearer {AUTH_TOKEN}', 'Content-Type': 'application/json'}\n",
    "BASE_PATH = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59220ff",
   "metadata": {},
   "source": [
    "## Function Definitions for Data Retrieval and Processing\n",
    "\n",
    "This section contains a set of Python functions designed to interact with a monitoring system's API to retrieve and process metrics related to executor performance. These functions fetch time-series data, compute statistical summaries, and determine key temporal boundaries (start and end times).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6bfd97",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def fetch_metric_range(metric, executor_id, start_time, end_time, step='16s'):\n",
    "    \"\"\"Fetches a specific metric over a range of time for a given executor.\"\"\"\n",
    "    query = f'{metric}{{executor_id=\"{executor_id}\"}}'\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'start': start_time,\n",
    "        'end': end_time,\n",
    "        'step': step\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Querying range: {query} from {start_time} to {end_time} with step {step}\")\n",
    "        response = requests.get(f\"{BASE_URL}/query_range\", params=params, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        results = response.json().get('data', {}).get('result', [])\n",
    "        \n",
    "        if results:\n",
    "            values = [float(item[1]) for item in results[0]['values']]\n",
    "            return {\n",
    "                'avg': np.mean(values),\n",
    "                'min': np.min(values),\n",
    "                'max': np.max(values),\n",
    "                'sum': np.sum(values),\n",
    "                'count': len(values),\n",
    "                'stddev': np.std(values),\n",
    "                'stdvar': np.var(values)\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data found for {metric} in range\")\n",
    "            return {agg: np.nan for agg in ['avg', 'min', 'max', 'sum', 'count', 'stddev', 'stdvar']}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {metric} for {executor_id}: {e}\")\n",
    "        return {agg: np.nan for agg in ['avg', 'min', 'max', 'sum', 'count', 'stddev', 'stdvar']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e5d4f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def fetch_latest_end_time(executor_id, time_range=\"32d\"):\n",
    "    \"\"\"Fetches the latest end time for a given executor_id within a time range.\"\"\"\n",
    "    query = f'worker_func_end_tstamp{{executor_id=\"{executor_id}\"}}[{time_range}]'\n",
    "    encoded_query = quote(query)\n",
    "    url = f\"{BASE_URL}/query?query={encoded_query}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        if data['status'] == 'success':\n",
    "            if data['data']['result']:\n",
    "                latest_timestamp = float('-inf')\n",
    "                for result in data['data']['result']:\n",
    "                    for timestamp, value in result['values']:\n",
    "                        latest_timestamp = max(latest_timestamp, float(timestamp))\n",
    "                return latest_timestamp\n",
    "            else:\n",
    "                print(f\"No end time data found for executor_id={executor_id}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error fetching end time: {data.get('error', 'Unknown error')}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching end time for {executor_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_earliest_start_time(executor_id, time_range=\"32d\"):\n",
    "    \"\"\"Fetches the earliest start time for a given executor_id within a time range.\"\"\"\n",
    "    query = f'worker_func_start_tstamp{{executor_id=\"{executor_id}\"}}[{time_range}]'\n",
    "    encoded_query = quote(query)\n",
    "    url = f\"{BASE_URL}/query?query={encoded_query}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        if data['status'] == 'success':\n",
    "            if data['data']['result']:\n",
    "                earliest_timestamp = float('inf')\n",
    "                for result in data['data']['result']:\n",
    "                    for timestamp, value in result['values']:\n",
    "                        earliest_timestamp = min(earliest_timestamp, float(timestamp))\n",
    "                return earliest_timestamp\n",
    "            else:\n",
    "                print(f\"No start time data found for executor_id={executor_id}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error fetching start time: {data.get('error', 'Unknown error')}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching start time for {executor_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_start_end_times(executor_id):\n",
    "    \"\"\"Fetches the earliest start time and latest end time for an executor_id.\"\"\"\n",
    "    try:\n",
    "        earliest_start_time = fetch_earliest_start_time(executor_id)\n",
    "        latest_end_time = fetch_latest_end_time(executor_id)\n",
    "        if earliest_start_time and latest_end_time:\n",
    "            start_time_iso = datetime.utcfromtimestamp(earliest_start_time).isoformat()\n",
    "            end_time_iso = datetime.utcfromtimestamp(latest_end_time).isoformat()\n",
    "            return start_time_iso, end_time_iso\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching start/end times for {executor_id}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f38744",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def extract_executor_data(base_path):\n",
    "    \"\"\"Extracts executor data from files in the specified directory with the appropriate pattern.\"\"\"\n",
    "    executor_data = []\n",
    "    pattern = re.compile(r'exec_ids_(\\d+)_splits(?:_v\\d+)?\\.csv')\n",
    "    \n",
    "    for file_name in os.listdir(base_path):\n",
    "        match = pattern.match(file_name)\n",
    "        if match:\n",
    "            file_path = os.path.join(base_path, file_name)\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                for _, row in df.iterrows():\n",
    "                    executor_id = row['executor_id']\n",
    "                    start_time, end_time = fetch_start_end_times(executor_id)\n",
    "                    \n",
    "                    if start_time and end_time:\n",
    "                        try:\n",
    "                            start_time_dt = datetime.fromisoformat(start_time)\n",
    "                            end_time_dt = datetime.fromisoformat(end_time)\n",
    "                            duration = (end_time_dt - start_time_dt).total_seconds()\n",
    "                        except ValueError:\n",
    "                            print(f\"Error converting dates for executor_id {executor_id}.\")\n",
    "                            start_time_dt, end_time_dt, duration = None, None, None\n",
    "                    else:\n",
    "                        start_time_dt, end_time_dt, duration = None, None, None\n",
    "                    \n",
    "                    executor_data.append({\n",
    "                        'executor_id': executor_id,\n",
    "                        'total_price_usd': row['total_price_usd'],\n",
    "                        'num_files': row['num_files'],\n",
    "                        'splits': row['splits'],\n",
    "                        'input_size_gb': row['input_size_gb'],\n",
    "                        'runtime_memory_mb': row['runtime_memory_mb'],\n",
    "                        'ephemeral_storage_mb': row['ephemeral_storage_mb'],\n",
    "                        'worker_processes': row['worker_processes'],\n",
    "                        'invoke_pool_threads': row['invoke_pool_threads'],\n",
    "                        'vcpus': row['vcpus'],\n",
    "                        'start_time': start_time_dt,\n",
    "                        'end_time': end_time_dt,\n",
    "                        'duration': duration\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"File {file_path} does not exist.\")\n",
    "    \n",
    "    df_executor_data = pd.DataFrame(executor_data)\n",
    "    \n",
    "    if df_executor_data.empty:\n",
    "        print(\"Warning: No data was extracted, the resulting DataFrame is empty.\")\n",
    "\n",
    "    return df_executor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777c999",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Extract data from executors\n",
    "df_metrics_exd = extract_executor_data(BASE_PATH)\n",
    "df_metrics_exd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1df875",
   "metadata": {},
   "source": [
    "## Data Processing: Feature Engineering and Outlier Removal\n",
    "\n",
    "This section outlines two essential data processing functions used to enhance the dataset before applying machine learning models: adding derived features and removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4173015",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    \"\"\"Adds new features to the DataFrame to enhance the model.\"\"\"\n",
    "    df['memory_per_file'] = df['runtime_memory_mb'] / df['num_files']\n",
    "    df['storage_per_file'] = df['ephemeral_storage_mb'] / df['num_files']\n",
    "    df['vcpus_per_file'] = df['vcpus'] / df['num_files']\n",
    "    df['files_per_vcpu'] = df['num_files'] / df['vcpus']\n",
    "    df['size_per_file'] = df['input_size_gb'] / df['num_files']\n",
    "    df['memory_per_gb'] = df['runtime_memory_mb'] / df['input_size_gb']\n",
    "    df['vcpus_per_gb'] = df['vcpus'] / df['input_size_gb']\n",
    "    df['storage_per_gb'] = df['ephemeral_storage_mb'] / df['input_size_gb']\n",
    "    df['threads_per_worker'] = df['invoke_pool_threads'] / df['worker_processes']\n",
    "    df['memory_per_thread'] = df['runtime_memory_mb'] / df['invoke_pool_threads']\n",
    "    df['vcpus_per_thread'] = df['vcpus'] / df['invoke_pool_threads']\n",
    "    df['memory_per_thread_vcpus_ratio'] = df['memory_per_thread'] / df['vcpus_per_thread']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7492f6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df_metrics = add_features(df_metrics_exd)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017f737",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "data = df_metrics.drop(columns=['executor_id', 'Unnamed: 0', 'total_price_usd', 'start_time', 'end_time'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ad020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713eb508",
   "metadata": {},
   "source": [
    "## Data Preparation: Splitting\n",
    "\n",
    "Preparing the data correctly is crucial for training a robust machine learning model. This step involves splitting the dataset into training and testing subsets and scaling the features to standardize their magnitudes.\n",
    "\n",
    "### Splitting the Data into Training and Testing Sets\n",
    "The dataset is divided into two subsets:\n",
    "- **Training Set (70%)**: Used to train the model.\n",
    "- **Testing Set (30%)**: Used to evaluate the model's performance on unseen data.\n",
    "\n",
    "The splitting is performed using `train_test_split` from `sklearn.model_selection`. The `random_state=42` ensures reproducibility of the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13ddab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Split data into 70% training and 30% testing\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fb2a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X_train = train_data.drop(columns=['duration'])\n",
    "y_train = train_data['duration']\n",
    "\n",
    "X_test = test_data.drop(columns=['duration'])\n",
    "y_test = test_data['duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f06503",
   "metadata": {},
   "source": [
    "## Feature Scaling: Standardization\n",
    "\n",
    "In this step, we standardize the features to ensure that all of them are on the same scale. Feature scaling is crucial when working with machine learning algorithms that are sensitive to the magnitude of features, such as gradient-based algorithms like XGBoost.\n",
    "\n",
    "### **StandardScaler**\n",
    "We use the `StandardScaler` from the `sklearn.preprocessing` module to standardize the features. This scaler transforms the data such that it has a mean of 0 and a standard deviation of 1, making the features comparable in terms of scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb310c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test set\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396d5d8",
   "metadata": {},
   "source": [
    "## Data Augmentation: Adding Gaussian Noise\n",
    "\n",
    "Data augmentation is a technique used to increase the diversity of the training dataset by artificially creating new samples. In this case, we augment the training data by adding Gaussian noise to the features. This helps the model generalize better by simulating slight variations in the data.\n",
    "\n",
    "### Adding Gaussian Noise\n",
    "Gaussian noise is generated with a mean of 0 and a specified standard deviation (`noise_level`). This noise is added to the features of the training dataset, creating a slightly modified version of the original data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ccf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(X, noise_level=0.01):\n",
    "    \"\"\"Adds Gaussian noise to the features.\"\"\"\n",
    "    noise = np.random.normal(loc=0.0, scale=noise_level, size=X.shape)\n",
    "    return X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the training data with Gaussian noise\n",
    "X_train_augmented = add_gaussian_noise(X_train_scaled, noise_level=0.02)\n",
    "\n",
    "# Combine the original and augmented training data\n",
    "X_train_final = np.vstack([X_train_scaled, X_train_augmented])\n",
    "y_train_final = np.concatenate([y_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cf2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size of X_train_final: {X_train_final.shape}\")\n",
    "print(f\"Size of y_train_final: {y_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed115b2",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna for XGBoost\n",
    "\n",
    "This section details the process of optimizing hyperparameters for the XGBoost model using **Optuna**, a powerful and efficient hyperparameter tuning library. By leveraging advanced optimization techniques, the tuning process ensures that the model is tailored for optimal performance on the geospatial dataset.\n",
    "\n",
    "### Overview of the Tuning Process\n",
    "\n",
    "The optimization process involves defining a search space for the hyperparameters that govern the XGBoost model's behavior. Key parameters include the maximum depth of the trees, learning rate, number of estimators, subsampling ratios, regularization terms, and feature sampling ratios. These parameters influence the model's complexity, ability to generalize, and computational efficiency.\n",
    "\n",
    "### Evaluation Strategy\n",
    "\n",
    "The model is evaluated using cross-validation, which divides the training data into multiple folds to ensure robust evaluation. To enhance stability, the target variable is transformed logarithmically, and its distribution is stratified into quantile bins. This stratification ensures balanced splits, preventing skewed evaluations caused by uneven data distributions.\n",
    "\n",
    "### Optuna Features\n",
    "\n",
    "Optuna efficiently searches the hyperparameter space by combining random sampling with intelligent exploration:\n",
    "- **Dynamic Pruning**: Trials that show poor early performance are terminated early, saving computational resources.\n",
    "- **Parallel Trials**: Multiple hyperparameter combinations are evaluated concurrently, reducing tuning time.\n",
    "- **Customized Objectives**: The optimization process directly targets minimizing the mean absolute error (MAE), aligning with the model's performance goals.\n",
    "\n",
    "### Benefits of Optimization\n",
    "\n",
    "The tuning process ensures the XGBoost model is highly effective for predicting the target variable by:\n",
    "- Reducing overfitting through regularization and careful sampling.\n",
    "- Balancing model complexity with computational efficiency.\n",
    "- Leveraging cross-validation to enhance generalization capabilities.\n",
    "\n",
    "This approach results in a fine-tuned XGBoost model capable of achieving optimal predictive performance for geospatial use cases, tailored to the nuances of the dataset and problem at hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f6f9b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    \"\"\"Objective function for XGBoost hyperparameter optimization using Optuna.\"\"\"\n",
    "    xgb_params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.05),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000, 5000),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.0, 0.5),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 1.0),\n",
    "        'eval_metric': 'mae',\n",
    "        'objective': 'reg:squarederror',\n",
    "        'verbosity': 0,\n",
    "        'tree_method': 'hist'  # Use 'hist' to utilize CPU instead of GPU\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor(**xgb_params, early_stopping_rounds=50, n_jobs=-1)\n",
    "\n",
    "    # Training and validation with cross-validation\n",
    "    X_train_array = np.array(X_train_final)\n",
    "    y_train_array = np.array(y_train_final).flatten()\n",
    "\n",
    "    y_train_log = np.log1p(y_train_array)\n",
    "    \n",
    "    num_bins = 5\n",
    "    y_binned = pd.qcut(y_train_log, q=num_bins, labels=False, duplicates='drop')\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X_train_array, y_binned):\n",
    "        X_t, X_v = X_train_array[train_idx], X_train_array[valid_idx]\n",
    "        y_t, y_v = y_train_log[train_idx], y_train_log[valid_idx]\n",
    "\n",
    "        xgb_model.fit(X_t, y_t, eval_set=[(X_v, y_v)], verbose=False)\n",
    "\n",
    "        preds = xgb_model.predict(X_v)\n",
    "        mae = mean_absolute_error(y_v, preds)\n",
    "        scores.append(mae)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc366e42",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "study_xgb = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "study_xgb.optimize(objective_xgb, n_trials=500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d5898",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "best_params_xgb = study_xgb.best_params\n",
    "print(f\"Best hyperparameters: {best_params_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50e12d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "xgb_best = XGBRegressor(**best_params_xgb, early_stopping_rounds=50, eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef30ca1",
   "metadata": {},
   "source": [
    "## Final Model Training and Predictions\n",
    "\n",
    "### Training the XGBoost Model\n",
    "\n",
    "With the optimal hyperparameters obtained through Optuna, the final XGBoost model is trained on the augmented training dataset. The target variable is log-transformed using `np.log1p()` to manage its skewed distribution and ensure that the model learns effectively from the data. \n",
    "\n",
    "During training:\n",
    "- The test set, with its log-transformed target, is used as the validation set for evaluation.\n",
    "- XGBoost monitors the validation set performance to adjust its learning process dynamically.\n",
    "\n",
    "### Generating Predictions\n",
    "\n",
    "Once the model is trained, predictions are made on the scaled test dataset:\n",
    "1. Predictions are initially made in the log-transformed space to match the training target's transformation.\n",
    "2. These predictions are reverted to their original scale using the exponential transformation `np.expm1()` for meaningful interpretation.\n",
    "\n",
    "### Key Outcomes\n",
    "\n",
    "This step finalizes the model's ability to generalize its learning to unseen data, ensuring accurate predictions while retaining interpretability. The use of logarithmic transformation and inverse scaling ensures the handling of non-linearities and data skewness effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4cc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the final training data\n",
    "y_train_log = np.log1p(y_train_final)\n",
    "xgb_best.fit(X_train_final, y_train_log, eval_set=[(X_test_scaled, np.log1p(y_test))], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38dc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and transform the predictions back to the original scale\n",
    "y_pred_log = xgb_best.predict(X_test_scaled)\n",
    "y_pred = np.expm1(y_pred_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70a4c0",
   "metadata": {},
   "source": [
    "## Model Evaluation and Analysis\n",
    "\n",
    "### Metrics Calculation\n",
    "To evaluate the performance of the trained XGBoost model, the following metrics are computed:\n",
    "1. **Mean Absolute Error (MAE):** Measures the average absolute differences between actual and predicted values, providing insight into overall prediction accuracy.\n",
    "2. **Mean Absolute Percentage Error (MAPE):** Reflects prediction accuracy as a percentage of the actual values, offering an intuitive understanding of the error magnitude.\n",
    "3. **R² Score:** Indicates the proportion of variance in the dependent variable that the model explains, demonstrating the quality of fit.\n",
    "\n",
    "### Cross-Validation\n",
    "The model undergoes 10-fold cross-validation to ensure its robustness. During this process:\n",
    "- The dataset is divided into 10 subsets, with 9 used for training and 1 for validation iteratively.\n",
    "- The mean MAE from all folds is calculated, providing a reliable measure of the model's performance across varying data partitions.\n",
    "\n",
    "### Configuration Analysis\n",
    "The test dataset is analyzed to identify:\n",
    "1. The configuration yielding the **lowest actual duration**.\n",
    "2. The configuration with the **lowest predicted duration**.\n",
    "   \n",
    "This comparison helps validate whether the model correctly identifies the optimal configuration.\n",
    "\n",
    "### Relative Error Analysis\n",
    "Relative errors are calculated as the absolute differences between actual and predicted durations, normalized by the actual values. A histogram visualizes the distribution of relative errors in the test set:\n",
    "- A tighter distribution indicates higher predictive accuracy.\n",
    "- Outliers, if present, suggest cases where the model struggles to generalize.\n",
    "\n",
    "### Visualization\n",
    "The distribution of relative errors is plotted to assess the model's reliability in predictions across different samples. \n",
    "\n",
    "### Insights\n",
    "1. If the configurations with the lowest actual and predicted durations match, the model demonstrates excellent predictive alignment.\n",
    "2. A low MAPE indicates the model's consistency in making precise predictions relative to the scale of the target variable.\n",
    "\n",
    "### Summary\n",
    "This evaluation not only confirms the model's predictive capabilities but also highlights areas for further refinement by analyzing instances of higher errors or mismatched optimal configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c2505",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Calculate MAE, MAPE, and R² on the original scale\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"MAPE: {mape:.2%}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_cv = XGBRegressor(**best_params_xgb)\n",
    "\n",
    "# Perform cross-validation and calculate the mean MAE\n",
    "cv_scores = cross_val_score(xgb_best_cv, X_train_final, y_train_final, cv=10, scoring='neg_mean_absolute_error')\n",
    "print(f\"Average MAE in cross-validation: {-cv_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d1f39",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with the test features and add the actual and predicted durations\n",
    "df_test = pd.DataFrame(X_test, columns=[\n",
    "    'splits', 'num_files', 'input_size_gb', 'runtime_memory_mb', 'ephemeral_storage_mb', \n",
    "    'worker_processes', 'invoke_pool_threads', 'vcpus', 'memory_per_file', 'storage_per_file', \n",
    "    'vcpus_per_file', 'files_per_vcpu', 'size_per_file', 'memory_per_gb', 'vcpus_per_gb', \n",
    "    'storage_per_gb', 'threads_per_worker', 'memory_per_thread', 'vcpus_per_thread'\n",
    "])\n",
    "df_test['duration'] = y_test\n",
    "df_test['predicted_duration'] = y_pred\n",
    "\n",
    "# Identify the configuration with the lowest actual duration and the lowest predicted duration\n",
    "min_duration_row = df_test.loc[df_test['duration'].idxmin()]\n",
    "min_predicted_duration_row = df_test.loc[df_test['predicted_duration'].idxmin()]\n",
    "\n",
    "# Print both configurations\n",
    "print(\"\\nConfiguration with the lowest actual duration:\")\n",
    "print(min_duration_row)\n",
    "\n",
    "print(\"\\nConfiguration with the lowest predicted duration:\")\n",
    "print(min_predicted_duration_row)\n",
    "\n",
    "# Check if they are the same row\n",
    "if min_duration_row.equals(min_predicted_duration_row):\n",
    "    print(\"\\nThe configuration with the lowest actual duration is the same as the one with the lowest predicted duration.\")\n",
    "else:\n",
    "    print(\"\\nThe configuration with the lowest actual duration is NOT the same as the one with the lowest predicted duration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be9d05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Calculate relative errors\n",
    "relative_errors = np.abs(y_test - y_pred) / y_test\n",
    "\n",
    "# Visualize the distribution of relative errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(relative_errors, bins=30, kde=True, color='purple')\n",
    "plt.xlabel('Relative Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Relative Errors in the Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"MAPE in the test set: {mape:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a1e54",
   "metadata": {},
   "source": [
    "## Residual and Scatter Plot Analysis\n",
    "\n",
    "### Residual Plot\n",
    "The residual plot visualizes the differences between actual and predicted durations, providing insights into the model's errors:\n",
    "- **Residuals:** Computed as the actual values minus the predicted values, they indicate whether predictions systematically overestimate or underestimate the actual durations.\n",
    "- **Key Features:**\n",
    "  - A horizontal red dashed line at zero residual indicates perfect predictions.\n",
    "  - Ideally, residuals should scatter randomly around this line without clear patterns, suggesting that the model captures the data trends effectively.\n",
    "  - Systematic patterns in residuals may indicate underfitting, overfitting, or unaccounted-for complexities in the data.\n",
    "\n",
    "### Scatter Plot of Actual vs. Predicted Durations\n",
    "This plot compares actual and predicted durations to assess the model's accuracy visually:\n",
    "- **Key Features:**\n",
    "  - A red dashed line represents the ideal fit where predictions perfectly match actual values.\n",
    "  - Data points closer to the line indicate more accurate predictions.\n",
    "  - Points deviating significantly suggest instances where the model struggles to make accurate predictions.\n",
    "\n",
    "### Purpose\n",
    "These visualizations provide an intuitive understanding of:\n",
    "1. The accuracy of the predictions across the dataset.\n",
    "2. Potential biases or inconsistencies in the model.\n",
    "3. Specific areas where model improvements may be necessary.\n",
    "\n",
    "### Insights\n",
    "- **Residual Plot:** Helps identify heteroscedasticity (variance inconsistency) or patterns indicating model issues.\n",
    "- **Scatter Plot:** Highlights the model's ability to predict durations effectively, with closer alignment to the ideal fit suggesting higher predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e0f70",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals, alpha=0.6, color='g')\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Duration')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1fac6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Scatter plot of actual vs predicted durations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, color='b')\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    color='r', linestyle='--', label='Ideal Fit'\n",
    ")\n",
    "plt.xlabel('Actual Duration')\n",
    "plt.ylabel('Predicted Duration')\n",
    "plt.title('Actual vs Predicted Duration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca56c2",
   "metadata": {},
   "source": [
    "## Baseline Model and Learning Curve Analysis\n",
    "\n",
    "### Baseline Prediction\n",
    "The baseline prediction uses the mean value of the training data as a simple model for comparison:\n",
    "- **Baseline MAE:** This metric measures the mean absolute error when predicting the same mean value for all test samples.\n",
    "- **Improvement Over Baseline:** Calculated as the percentage reduction in MAE achieved by the model compared to the baseline.\n",
    "\n",
    "#### Insights:\n",
    "- A significant improvement over the baseline MAE indicates that the model has learned patterns beyond a simple average prediction.\n",
    "\n",
    "### Learning Curve Analysis\n",
    "The learning curve helps visualize how the model's performance changes as the training set size increases:\n",
    "- **Training Errors:** Reflect how well the model fits the training data.\n",
    "- **Testing Errors:** Indicate generalization ability on unseen data.\n",
    "\n",
    "#### Key Features:\n",
    "- **Early Stopping:** Prevents overfitting by halting training if performance on a validation set does not improve after a set number of rounds.\n",
    "- **Trend Analysis:** \n",
    "  - A decreasing training error with increasing data suggests improved model fitting.\n",
    "  - A small gap between training and testing errors implies good generalization.\n",
    "  - A persistent gap might indicate overfitting or underfitting.\n",
    "\n",
    "### Histogram of Actual vs Predicted Durations\n",
    "This histogram compares the distributions of actual and predicted durations:\n",
    "- **Kernel Density Estimation (KDE):** Provides a smoothed visualization of the underlying distributions.\n",
    "- **Key Observations:**\n",
    "  - A high overlap between the two curves suggests accurate predictions.\n",
    "  - Divergences indicate areas where the model may struggle to capture complexities in the data.\n",
    "\n",
    "#### Overall Importance\n",
    "These analyses provide a comprehensive understanding of:\n",
    "1. The model's relative performance against a naive baseline.\n",
    "2. Its learning dynamics and generalization capability.\n",
    "3. The alignment of predicted distributions with actual outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5343a93",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Baseline prediction using mean of training data\n",
    "y_baseline = np.full_like(y_test, y_train.mean())\n",
    "mae_baseline = mean_absolute_error(y_test, y_baseline)\n",
    "print(f\"MAE of the baseline model: {mae_baseline:.2f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement_mae = 100 * (mae_baseline - mae) / mae_baseline\n",
    "print(f\"Improvement over baseline MAE: {improvement_mae:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X_train, y_train, X_test, y_test, early_stopping_rounds=50):\n",
    "    \"\"\"Plots the learning curve for a given model using MAE as the metric.\"\"\"\n",
    "    train_errors, test_errors = []\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)  # Use KFold for regression\n",
    "    \n",
    "    for m in range(1, len(X_train)):\n",
    "        # Ensure X_train[:m] and y_train[:m] have the same dimensions\n",
    "        X_train_subset = X_train[:m]\n",
    "        y_train_subset = y_train[:m]\n",
    "        \n",
    "        # Train the model using a validation set (eval_set) for early stopping\n",
    "        model.fit(\n",
    "            X_train_subset, y_train_subset, \n",
    "            eval_set=[(X_test, y_test)], \n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Calculate errors on the training and test sets using MAE\n",
    "        y_train_predict = model.predict(X_train_subset)\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        \n",
    "        train_errors.append(mean_absolute_error(y_train_subset, y_train_predict))  # MAE on training set\n",
    "        test_errors.append(mean_absolute_error(y_test, y_test_predict))  # MAE on test set\n",
    "    \n",
    "    # Plot the learning curves with MAE\n",
    "    plt.plot(train_errors, \"r-+\", linewidth=2, label=\"train (MAE)\")\n",
    "    plt.plot(test_errors, \"b-\", linewidth=3, label=\"test (MAE)\")\n",
    "    plt.xlabel(\"Training set size\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the figure in SVG format\n",
    "    plt.savefig(\"learning_curve.svg\", format=\"svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad141ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot the learning curve with early stopping rounds\n",
    "plot_learning_curve(xgb_best, X_train_final, y_train_final, X_test_scaled, y_test, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98acae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram with KDE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_test, color='blue', label='Actual', kde=True)\n",
    "sns.histplot(y_pred, color='red', label='Predicted', kde=True)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Histogram of Actual and Predicted Values with KDE')\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdfeb5e",
   "metadata": {},
   "source": [
    "## Linear Regression Model: Analysis and Comparison with XGBoost\n",
    "\n",
    "### Linear Regression Model\n",
    "1. **Model Training:** A simple linear regression model is trained using the scaled features from the training dataset. This approach assumes a linear relationship between the input features and the target variable (duration).\n",
    "2. **Performance Metrics:**\n",
    "   - **Mean Absolute Error (MAE):** Quantifies the average absolute difference between actual and predicted values.\n",
    "   - **Mean Absolute Percentage Error (MAPE):** Indicates prediction error as a percentage of actual values, useful for relative comparisons.\n",
    "   - **R² Score:** Measures the proportion of variance in the target variable explained by the model. Higher values close to 1 indicate better performance.\n",
    "\n",
    "### Comparison with XGBoost\n",
    "1. **Performance Metrics for XGBoost:**\n",
    "   - Lower MAE and MAPE values demonstrate XGBoost's ability to model complex, non-linear relationships better than linear regression.\n",
    "   - A higher R² score signifies a better fit and predictive power.\n",
    "2. **Improvement Over Linear Regression:**\n",
    "   - The percentage improvement in MAE highlights the superiority of XGBoost in handling the given data complexity.\n",
    "\n",
    "### Prediction Comparison Visualization\n",
    "- **Scatter Plot:**\n",
    "  - Compares actual durations against predictions from both models.\n",
    "  - Points closer to the red diagonal (ideal fit) indicate more accurate predictions.\n",
    "  - XGBoost predictions show better alignment with actual durations compared to linear regression, as evidenced by reduced scatter.\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Model Suitability:** While linear regression provides a baseline understanding, its simplicity limits its performance on complex datasets.\n",
    "2. **XGBoost Advantages:** Leveraging advanced tree-based methods, XGBoost captures intricate patterns and outperforms linear regression on all evaluated metrics.\n",
    "3. **Practical Implications:** For datasets with non-linear relationships and feature interactions, XGBoost or other advanced models are preferred over linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6320e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "linear_model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict durations with the scaled test set\n",
    "y_pred_linear = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MAE, MAPE, and R²\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "mape_linear = mean_absolute_percentage_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "print(f\"Linear Regression - MAE: {mae_linear:.2f}\")\n",
    "print(f\"Linear Regression - MAPE: {mape_linear:.2%}\")\n",
    "print(f\"Linear Regression - R²: {r2_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of Models:\")\n",
    "print(f\"XGBoost - MAE: {mae:.2f}, MAPE: {mape:.2%}, R²: {r2:.4f}\")\n",
    "print(f\"Linear Regression - MAE: {mae_linear:.2f}, MAPE: {mape_linear:.2%}, R²: {r2_linear:.4f}\")\n",
    "\n",
    "# Compare the improvement in MAE between XGBoost and linear regression\n",
    "improvement_over_linear = 100 * (mae_linear - mae) / mae_linear\n",
    "print(f\"Improvement over Linear Regression MAE: {improvement_over_linear:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction comparisons\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, color='blue', label='XGBoost Predictions')\n",
    "sns.scatterplot(x=y_test, y=y_pred_linear, alpha=0.6, color='green', label='Linear Regression Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel('Actual Duration')\n",
    "plt.ylabel('Predicted Duration')\n",
    "plt.title('Actual vs Predicted Duration: XGBoost vs Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa585a08",
   "metadata": {},
   "source": [
    "## PCA + Linear Regression: Model Analysis and Comparison\n",
    "\n",
    "### Principal Component Analysis (PCA) for Dimensionality Reduction\n",
    "1. **Goal of PCA:** PCA is used to reduce the dimensionality of the data by transforming it into a set of linearly uncorrelated variables (principal components). This transformation helps in improving the model's performance by focusing on the most significant features and reducing noise from less important dimensions.\n",
    "2. **Choosing the Number of Components:** In this case, `n_components` is set to 6, meaning the model uses the first 6 principal components. This number can be adjusted depending on the data variance captured by these components.\n",
    "3. **Training the Model:**\n",
    "   - PCA is applied to both the training and test datasets.\n",
    "   - A linear regression model is then trained on the transformed training data (using the principal components), and predictions are made on the test set.\n",
    "\n",
    "### Performance Metrics for PCA + Linear Regression\n",
    "1. **MAE (Mean Absolute Error):** A lower MAE indicates that the predictions are closer to the actual values, suggesting the model's accuracy.\n",
    "2. **MAPE (Mean Absolute Percentage Error):** A useful percentage metric for assessing relative prediction accuracy.\n",
    "3. **R² Score:** Measures how well the model explains the variance in the data. Higher values indicate better predictive performance.\n",
    "\n",
    "### Model Comparison: XGBoost vs Linear Regression vs PCA + Linear Regression\n",
    "- **XGBoost:** A tree-based ensemble method that is well-suited for capturing complex relationships in the data. It generally performs better than linear models in terms of handling non-linearities and feature interactions.\n",
    "- **Linear Regression:** A basic linear approach that is easy to interpret but often less effective for complex datasets.\n",
    "- **PCA + Linear Regression:** By using PCA to reduce dimensionality, we simplify the dataset before applying linear regression. While this may help in cases with high multicollinearity or noise, it may still not capture complex relationships as well as XGBoost.\n",
    "\n",
    "### MAE Improvement Comparison\n",
    "1. **Improvement Over Linear Regression:** XGBoost significantly outperforms linear regression, as expected, due to its ability to capture non-linear relationships.\n",
    "2. **Improvement Over PCA + Linear Regression:** PCA improves the linear regression model by reducing dimensionality and potentially mitigating overfitting, but it still does not match the performance of XGBoost.\n",
    "\n",
    "### Prediction Comparison Visualization\n",
    "- **Scatter Plot:** The plot compares the actual vs predicted values for each model:\n",
    "  - XGBoost predictions align better with the actual values.\n",
    "  - Linear Regression and PCA + Linear Regression also make predictions, but they show more deviation from the ideal fit (red dashed line).\n",
    "\n",
    "### Key Takeaways\n",
    "1. **XGBoost is the best model** for this dataset, especially for capturing complex patterns and interactions.\n",
    "2. **PCA + Linear Regression** can be a useful alternative when dealing with highly-dimensional data but does not match the predictive power of more complex models like XGBoost.\n",
    "3. **Linear Regression** serves as a baseline model, helpful for understanding the simplest possible relationships in the data but often outperformed by more advanced methods.\n",
    "\n",
    "### Conclusion\n",
    "In summary, while linear regression and PCA + linear regression are useful techniques for baseline and reduced-dimensionality models, XGBoost stands out in terms of predictive accuracy. The use of PCA with linear regression provides some improvement but still falls short compared to XGBoost's capabilities in handling non-linear relationships and complex feature interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d754f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of principal components for PCA\n",
    "n_components = 6  # Adjust this number as needed\n",
    "\n",
    "# Apply PCA on the training set\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_final)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Create the linear regression model\n",
    "linear_model_pca = LinearRegression()\n",
    "\n",
    "# Fit the model to the PCA-reduced training data\n",
    "linear_model_pca.fit(X_train_pca, y_train_final)\n",
    "\n",
    "# Predict durations on the PCA-reduced test set\n",
    "y_pred_pca = linear_model_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate MAE, MAPE, and R² for linear regression with PCA\n",
    "mae_pca = mean_absolute_error(y_test, y_pred_pca)\n",
    "mape_pca = mean_absolute_percentage_error(y_test, y_pred_pca)\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "\n",
    "print(f\"PCA + Linear Regression - MAE: {mae_pca:.2f}\")\n",
    "print(f\"PCA + Linear Regression - MAPE: {mape_pca:.2%}\")\n",
    "print(f\"PCA + Linear Regression - R²: {r2_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5badd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nComparison of Models:\")\n",
    "print(f\"XGBoost - MAE: {mae:.2f}, MAPE: {mape:.2%}, R²: {r2:.4f}\")\n",
    "print(f\"Linear Regression - MAE: {mae_linear:.2f}, MAPE: {mape_linear:.2%}, R²: {r2_linear:.4f}\")\n",
    "print(f\"PCA + Linear Regression - MAE: {mae_pca:.2f}, MAPE: {mape_pca:.2%}, R²: {r2_pca:.4f}\")\n",
    "\n",
    "# Compare the improvement in MAE between XGBoost and the linear regression models\n",
    "improvement_over_linear = 100 * (mae_linear - mae) / mae_linear\n",
    "improvement_over_pca_linear = 100 * (mae_pca - mae) / mae_pca\n",
    "\n",
    "print(f\"Improvement over Linear Regression MAE: {improvement_over_linear:.2f}%\")\n",
    "print(f\"Improvement over PCA + Linear Regression MAE: {improvement_over_pca_linear:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4422c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction comparisons\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, color='blue', label='XGBoost Predictions')\n",
    "sns.scatterplot(x=y_test, y=y_pred_linear, alpha=0.6, color='green', label='Linear Regression Predictions')\n",
    "sns.scatterplot(x=y_test, y=y_pred_pca, alpha=0.6, color='orange', label='PCA + Linear Regression Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel('Actual Duration')\n",
    "plt.ylabel('Predicted Duration')\n",
    "plt.title('Actual vs Predicted Duration: XGBoost vs Linear Regression vs PCA + Linear Regression')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as an SVG file\n",
    "plt.savefig(\"act_vs_pred_duration.svg\", format='svg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01f91c",
   "metadata": {},
   "source": [
    "### Cross-Validation and Residual Analysis\n",
    "\n",
    "- **Linear Regression (Cross-Validation MAE):**\n",
    "  We performed cross-validation on the Linear Regression model using 5 folds and calculated the **Mean Absolute Error (MAE)** for each fold. The average MAE was computed and provided as the model's performance metric.\n",
    "  \n",
    "- **PCA + Linear Regression (Cross-Validation MAE):**\n",
    "  Similarly, we applied Principal Component Analysis (PCA) to reduce the dimensionality of the data before performing Linear Regression. Cross-validation was also conducted on this PCA-transformed data, and the average MAE was computed.\n",
    "\n",
    "- **Comparison of Models:**\n",
    "  The **average MAE** values from the cross-validation results of both models are as follows:\n",
    "  - **Linear Regression**: MAE of `average_mae_cv_linear`.\n",
    "  - **PCA + Linear Regression**: MAE of `average_mae_cv_pca`.\n",
    "\n",
    "- **Residuals Analysis:**\n",
    "  The residuals for the following models were calculated by subtracting the predicted values from the actual values:\n",
    "  - **XGBoost residuals**: The difference between the predicted values from XGBoost and the actual test data.\n",
    "  - **Linear Regression residuals**: The difference between the predicted values from the Linear Regression model and the actual test data.\n",
    "  - **PCA + Linear Regression residuals**: The difference between the PCA + Linear Regression model's predicted values and the actual test data.\n",
    "\n",
    "- **Comparative Residual Plot:**\n",
    "  A residual plot was created comparing the residuals for XGBoost, Linear Regression, and PCA + Linear Regression. This plot helps visually assess the spread of residuals for each model, with the following features:\n",
    "  - **XGBoost residuals** are plotted in green.\n",
    "  - **Linear Regression residuals** are plotted in blue.\n",
    "  - **PCA + Linear Regression residuals** are plotted in red.\n",
    "  \n",
    "  A horizontal line at 0 is added to indicate no residual error.\n",
    "\n",
    "- **Saved Output:**\n",
    "  The comparative residual plot was saved as an SVG file titled `residual_plot_comparison.svg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f24d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model\n",
    "linear_model_cv = LinearRegression()\n",
    "\n",
    "# Define MAE as a scorer for cross-validation\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Perform cross-validation for Linear Regression\n",
    "mae_cv_linear = cross_val_score(linear_model_cv, X_train_final, y_train_final, \n",
    "                                scoring=mae_scorer, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model for PCA-transformed data\n",
    "linear_model_pca_cv = LinearRegression()\n",
    "\n",
    "# Perform cross-validation for PCA + Linear Regression\n",
    "mae_cv_pca = cross_val_score(linear_model_pca_cv, X_train_pca, y_train_final, \n",
    "                             scoring=mae_scorer, cv=5)\n",
    "\n",
    "# Calculate the average MAE from the cross-validation results and convert to positive\n",
    "average_mae_cv_linear = -np.mean(mae_cv_linear)\n",
    "average_mae_cv_pca = -np.mean(mae_cv_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average MAE (Cross-Validation) - Linear Regression: {average_mae_cv_linear:.2f}\")\n",
    "print(f\"Average MAE (Cross-Validation) - PCA + Linear Regression: {average_mae_cv_pca:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd086d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for each model\n",
    "residuals_xgb = y_test - y_pred\n",
    "residuals_linear = y_test - y_pred_linear\n",
    "residuals_pca = y_test - y_pred_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21330462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparative residuals\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# XGBoost residuals\n",
    "sns.scatterplot(x=y_pred, y=residuals_xgb, alpha=0.6, color='g', label='XGBoost Residuals')\n",
    "\n",
    "# Linear regression residuals\n",
    "sns.scatterplot(x=y_pred_linear, y=residuals_linear, alpha=0.6, color='b', label='Linear Regression Residuals')\n",
    "\n",
    "# PCA + Linear regression residuals\n",
    "sns.scatterplot(x=y_pred_pca, y=residuals_pca, alpha=0.6, color='r', label='PCA + Linear Regression Residuals')\n",
    "\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Predicted Duration')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residual Plot Comparison: XGBoost vs. Linear Regression vs. PCA + Linear Regression')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as an SVG file\n",
    "plt.savefig(\"residual_plot_comparison.svg\", format='svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ws",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
